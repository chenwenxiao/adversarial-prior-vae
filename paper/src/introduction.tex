\section{Introduction}

How to learn deep generative models that are able to capture complex data pattern in high dimension space, \EG image datasets, is one of the major challenges in machine learning. Many approaches to train generative models by distinct training objectives are proposed in the past, \EG Generative Adversarial Networks (GAN)~\cite{goodfellow2014generative}, Flow-based models~\cite{dinh2016density,kingma2018glow}, PixelCNN~\cite{van2016conditional}, and Variational Autoencoders (VAE)~\cite{kingma2014auto,rezende_stochastic_2014}.

VAE uses the variational inference and re-parameterization trick to optimize the evidence lower bound of log-likelihood (ELBO). In the past, many researches focused on enriching variational posterior~\cite{kingma2016improved,tomczak2016improving}, but recently some researches show that the standard Gaussian prior could lead to underfitting in latent space, harmful to the performance of VAE~\cite{tomczak2018vae}. To enrich prior, several learnable prior are proposed~\cite{tomczak2018vae,bauer2019resampled,takahashi2019variational}. Most of them focus on the approximating aggregated posterior which is the integral of variational posterior and is shown as the optimal prior to minimize ELBO. However, existing methods based on aggregated posterior reaches limited performance. Recently, we notice that the discriminator can assess the quality of data and \textbf{We argue that it is advisable to adjust learnable prior by a discriminator which has more clear meaning than approximation for aggregated posterior. }

We propose Pull-back Prior, base on Wasserstein distance~\cite{arjovsky2017wasserstein} and learnable prior. The key idea is to adjust the density of prior by a discriminator that can assess the quality of data. 
Firstly, a discriminator $D(x)$ is trained for assessing the quality of images. Then, this discriminator is \textit{pulled back} to latent space, defined by $D(G(z))$, where $G(z)$ is the generator. Finally, we adjust prior distribution according to the pull-back discriminator. 
%The inference of pull-back prior is similar to the proof that shows aggregated posterior as optimal prior. 
%The key difference is that we search the prior that minimizes the Wasserstein distance between empirical distribution and model distribution instead of ELBO (if so, we will obtain aggregated posterior). 

We propose a training algorithm for VAE with Pull-back Prior (VAEPP), based on SGVB~\cite{kingma2014auto} and WGAN gradient penalty terms, which mixes Wasserstein distance into VAE and extends to a more general VAE framework. We also use Langevin Dynamics to improve the sampling of quality. 
Thanks to the gradient penalty term of WGAN-GP~\cite{gulrajani2017improved} and WGAN-div~\cite{wu2018wasserstein}, and the practical implementation of Langevin dynamics in MEG~\cite{kumar2019maximum}, we enjoy stable efficient training and sampling process. 
% In these years, out-of-distribution (OoD) is noticed by some researchers, and \cite{nalisnick2018deep} has shown that the model log-likelihood from flow-based models, VAEs, and PixelCNN assign higher density to the images of SVHN~\cite{netzer2011reading} when these models are trained on CIFAR-10 and such peculiar behavior of these models also act on other dataset. It challenges the assumption of generative models that the density of in-distribution is higher and the density of out-of-distribution is lower. In this paper, we will show that the discriminator and the norm of its gradient are as our expectation in VAEPP. It reminds us to use these indicators to help VAE to outcome the OoD problem, and it reaches a powerful performance in OoD testing.

The main contributions of this paper are the following:
\begin{itemize}
	\item We propose novel and powerful Pull-back Prior, derived by minimizing the Wasserstein distance between model distribution and empirical distribution. 
	\item We propose VAEPP framework to use existing techniques of VAE, \EG flow posterior, and WGAN, \EG gradient penalty strategy, to improve the log-likelihood, sampling quality and stability of training. 
	\item In log-likelihood metrics, VAEPP outperforms the models without autoregressive components and is comparable to the autoregressive models on vast common datasets. In FID and IS metrics, it is comparable to GANs and SOTA of VAE on vast common datasets. 
	% \item The combination indicator of VAEPP which involves the log-likelihood and discriminator outperforms other existing OoD detector in OoD testing.
\end{itemize}
