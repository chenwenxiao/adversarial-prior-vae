\section{Introduction}

How to learn deep generative models that are able to capture complex data pattern in high dimension space, \EG image datasets, is one of the major challenges in machine learning. Many approaches to training generative models by distinct training objectives have been proposed in the past, \EG Generative Adversarial Networks (GAN)~\cite{goodfellow2014generative}, Flow-based models~\cite{dinh2016density,kingma2018glow}, PixelCNN~\cite{van2016conditional}, and Variational Autoencoders (VAE)~\cite{kingma2014auto,rezende_stochastic_2014}.

VAE uses the variational inference and re-parameterization trick to optimize the evidence lower bound of log-likelihood (ELBO). In the past, many researches~\cite{kingma2016improved,tomczak2016improving} focused on enriching the variational posterior, but recently \cite{tomczak2018vae} showed that the standard Gaussian prior could lead to underfitting in latent space, harmful to the performance of VAEs. To enrich the prior, several learnable priors have been proposed~\cite{tomczak2018vae,bauer2019resampled,takahashi2019variational}. Most of them focus on approximating aggregated posterior which is the integral of the variational posterior and is shown as the optimal prior to minimize ELBO. However, existing methods based on the aggregated posterior reach limited performance, and the practical meaning of the aggregated posterior is blurry. Recently, we notice that the discriminator can assess the quality of data and \textbf{we argue that it is advisable to adjust the learnable prior by a discriminator which has clearer practical meaning than approximating the aggregated posterior. } 

We propose Pull-back Prior, based on the discriminator and a learnable prior. 
Firstly, a discriminator $D(x)$ is trained for assessing the quality of images. Then, we define a pull-back discriminator on latent space, by $D(G(z))$, where $G(z)$ is the generator (notion \textit{pull-back} is from mathematics). Finally, we adjust the density of the prior according to the pull-back discriminator. 
%The inference of pull-back prior is similar to the proof that shows aggregated posterior as optimal prior. 
%The key difference is that we search the prior that minimizes the Wasserstein distance between empirical distribution and model distribution instead of ELBO (if so, we will obtain aggregated posterior). 

We propose a training algorithm for VAE with Pull-back Prior (VAEPP), based on SGVB~\cite{kingma2014auto} with gradient penalty terms, which mix the discriminator and the gradient penalty term into VAE. We extend it to a more general VAE framework. We also use Langevin Dynamics to improve the quality of sampling. 
Thanks to the gradient penalty term of WGAN-GP~\cite{gulrajani2017improved} and WGAN-div~\cite{wu2018wasserstein}, and the practical implementation of Langevin dynamics in MEG~\cite{kumar2019maximum}, we enjoy stable efficient training and sampling process. 
% In these years, out-of-distribution (OoD) is noticed by some researchers, and \cite{nalisnick2018deep} has shown that the model log-likelihood from flow-based models, VAEs, and PixelCNN assign higher density to the images of SVHN~\cite{netzer2011reading} when these models are trained on CIFAR-10 and such peculiar behavior of these models also act on other dataset. It challenges the assumption of generative models that the density of in-distribution is higher and the density of out-of-distribution is lower. In this paper, we will show that the discriminator and the norm of its gradient are as our expectation in VAEPP. It reminds us to use these indicators to help VAE to outcome the OoD problem, and it reaches a powerful performance in OoD testing.

The main contributions of this paper are in the following:
\begin{itemize}
	\item We propose a novel and powerful learnable prior, Pull-back Prior, which is adjusted by a discriminator that can assess the quality of data. 
	\item We propose VAEPP framework to use existing techniques of VAE, \EG flow posterior, and WGAN, \EG gradient penalty strategy, and Langevin Dynamics to improve the log-likelihood, quality of sampling and stability of training. 
	\item In MNIST and CIFAR-10, the log-likelihood of VAEPP outperforms models without autoregressive components and is comparable to autoregressive models. In MNIST, Fashion-MNIST, CIFAR-10 and CelebA,  the FID of VAEPP is comparable to GANs and SOTA of VAEs. 
	% \item The combination indicator of VAEPP which involves the log-likelihood and discriminator outperforms other existing OoD detector in OoD testing.
\end{itemize}
