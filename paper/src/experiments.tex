\section{Experiments}
We test VAEPP in vast common datasets including MNIST, Fashion-MNIST, CIFAR-10 and CELEBA. 
We will firstly use some experiments to show the selection of hyper-parameters in CIFAR-10. And then we will test the performance on other dataset without fine-turn hyper-parameters. In the 2nd subsection, we will show the quality of sampling. In the 3rd subsection, we will show how VAEPP solve the out-of-distribution problem. 
\subsection{Log-likelihood}

\begin{table}
\centering
\begin{tabular}{lrr}  
\toprule
Model  &  $-\log p_\theta(x)$ \\
\midrule
Results with autoregressive   \\
PIXELCNN         &  81.30      \\
DRAW             &  80.97      \\
IAFVAE           &  79.88      \\
PIXELVAE         &  79.66      \\
PIXELRNN         &  79.20      \\
VLAE             &  79.03      \\
PixelHVAE with VampPrior        &  78.45      \\
\midrule
Results without autoregressive   \\
DISCRETE VAE     &  81.01      \\
\midrule
Results without learnable prior   \\
VampPrior        &  79.75      \\
LARS             &  80.30     \\
VAEPP            &  TODO      \\
Improved VAEPP   &  TODO      \\
\bottomrule
\end{tabular}
\caption{Test log-likelihood on MNIST}
\label{tab:mnist-nll}
\end{table}



\subsection{Quality of Sampling}


\subsection{Out-of-Distribution}


